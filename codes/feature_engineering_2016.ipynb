{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramezani/anaconda/lib/python2.7/site-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# import some libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the properties and merge with coord\n",
      "Size of the properties data frame:  (2985217, 58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramezani/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2871: DtypeWarning: Columns (23,33,35,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/\"\n",
    "print(\"Read the properties and merge with coord\")\n",
    "prop = pd.read_csv(path + 'renamed_properties_2016.csv')\n",
    "prop = prop.drop(\"Unnamed: 0\", axis=1)\n",
    "print \"Size of the properties data frame: \", prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the properties data frame:  (2985217, 55)\n"
     ]
    }
   ],
   "source": [
    "# drop two constant features and fips. These features don't contain any information\n",
    "prop = prop.drop([\"flag_tub\", \"flag_fireplace\", \"fips\"], axis=1)\n",
    "print \"Size of the properties data frame: \", prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the properties data frame:  (2973780, 55)\n"
     ]
    }
   ],
   "source": [
    "# Drop missing rows from prop\n",
    "index = pd.isnull(prop[\"latitude\"])\n",
    "prop = prop[~index]\n",
    "print \"Size of the properties data frame: \", prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# classify features to three classes. These helps us later\n",
    "number = [\"num_bathroom\", \"num_bedroom\", \"num_bathroom_calc\", \"num_fireplace\", \"num_bath\", \"num_garage\", \"num_pool\", \n",
    "          \"num_room\", \"num_75_bath\", \"num_unit\", \"num_story\"]\n",
    "quality = [\"type_aircon\", \"type_architectural\", \"type_framing\", \"type_quality\", \"type_deck\", \"type_heating\", \n",
    "           \"pooltypeid10\", \"pooltypeid2\", \"pooltypeid7\", \"type_zoning_landuse\", \"type_story\", \"type_material\"]\n",
    "position = [\"region_city\", \"region_county\", \"region_neighbor\", \"region_zip\", \"zoning_landuse_county\", \n",
    "             \"zoning_property\", \"censustractandblock\", \"rawcensustractandblock\"]\n",
    "tax3 = [\"tax_delinquency\"]\n",
    "ll = number + quality + position + tax3\n",
    "\n",
    "print len(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the training data\n",
      "Size of the train data frame:  (90275, 56)\n"
     ]
    }
   ],
   "source": [
    "print(\"Read the training data\")\n",
    "train = pd.read_csv(path + 'renamed_train_2016.csv', parse_dates=['date'])\n",
    "train = train.drop(\"Unnamed: 0\", axis=1)\n",
    "train[\"month\"] = train['date'].dt.month\n",
    "\n",
    "#Merge train and prop\n",
    "train = pd.merge(train, prop, how='left', on='id_parcel')\n",
    "\n",
    "train = train.drop(['id_parcel', 'date'], axis=1)\n",
    "print \"Size of the train data frame: \", train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop['latitude'] = prop['latitude'] / 1e6\n",
    "prop['longitude'] = prop['longitude'] / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_bathroom              25\n",
       "num_bedroom               13\n",
       "num_bathroom_calc     117475\n",
       "num_fireplace        2661143\n",
       "num_bath              117475\n",
       "num_garage           2090513\n",
       "num_pool             2456246\n",
       "num_room                  38\n",
       "num_75_bath          2662149\n",
       "num_unit              996290\n",
       "num_story            2291711\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of missing values in number features\n",
    "number = [\"num_bathroom\", \"num_bedroom\", \"num_bathroom_calc\", \"num_fireplace\", \"num_bath\", \"num_garage\", \"num_pool\", \n",
    "          \"num_room\", \"num_75_bath\", \"num_unit\", \"num_story\"]\n",
    "pd.isnull(prop[number]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_bathroom\n",
      "Number of classes:  14\n",
      "num_bedroom\n",
      "Number of classes:  11\n",
      "num_bathroom_calc\n",
      "Number of classes:  14\n",
      "num_fireplace\n",
      "Number of classes:  6\n",
      "num_bath\n",
      "Number of classes:  9\n",
      "num_garage\n",
      "Number of classes:  7\n",
      "num_pool\n",
      "Number of classes:  3\n",
      "num_room\n",
      "Number of classes:  11\n",
      "num_75_bath\n",
      "Number of classes:  4\n",
      "num_unit\n",
      "Number of classes:  7\n",
      "num_story\n",
      "Number of classes:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramezani/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fix_number(target, threshold = 200, na_value = 0):\n",
    "    '''\n",
    "    this function imputes the missing values. For numerical features, it replaces them with zero,\n",
    "    and for catergorical features, it groups them into a new feature. It also combines the rare events\n",
    "    with the frequency threshold of less than 200 (for example houses with 15 bedrooms) into one group\n",
    "    to avoid overfitting. \n",
    "    '''\n",
    "    X = train[target].fillna(na_value)\n",
    "    max_target = 10000000\n",
    "    \n",
    "    density = X.value_counts()\n",
    "    index = density.index\n",
    "    rare = density[density < threshold].index\n",
    "    X.loc[X.isin(rare)] = max_target\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(X))\n",
    "    \n",
    "    Y = pd.DataFrame(prop[[\"id_parcel\", target]])\n",
    "    Y[target] = Y[target].fillna(na_value)\n",
    "    \n",
    "    known = Y[target].isin(index)\n",
    "    Y_known = Y[known]\n",
    "    Y_unknown = Y[~known]\n",
    "    \n",
    "    Y_known.loc[Y_known[target].isin(rare), target] = max_target\n",
    "    Y_known.loc[:, target] = lbl.transform(Y_known[target].values)\n",
    "    \n",
    "    print \"Number of classes: \", Y_known.loc[:, target].max() + 2\n",
    "    Y_unknown.loc[:, target] = Y_known.loc[:, target].max() + 1\n",
    "    \n",
    "    prop.loc[known, target] = Y_known[target].values\n",
    "    prop.loc[~known, target] = Y_unknown[target].values\n",
    "\n",
    "# Impute missing numerical values with zero\n",
    "for ii in number:\n",
    "    print ii\n",
    "    fix_number(ii, threshold = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_aircon           2162261\n",
       "type_architectural    2967719\n",
       "type_framing          2961151\n",
       "type_quality          1035292\n",
       "type_deck             2956684\n",
       "type_heating          1167379\n",
       "pooltypeid10          2936841\n",
       "pooltypeid2           2941705\n",
       "pooltypeid7           2488321\n",
       "type_story            2972156\n",
       "type_material         2967033\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of missing values in quality features\n",
    "quality = [\"type_aircon\", \"type_architectural\", \"type_framing\", \"type_quality\", \"type_deck\", \"type_heating\", \n",
    "           \"pooltypeid10\", \"pooltypeid2\", \"pooltypeid7\", \"type_story\", \"type_material\"]\n",
    "pd.isnull(prop[quality]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  6\n",
      "Number of classes:  4\n",
      "Number of classes:  3\n",
      "Number of classes:  7\n",
      "Number of classes:  3\n",
      "Number of classes:  7\n",
      "Number of classes:  3\n",
      "Number of classes:  3\n",
      "Number of classes:  3\n",
      "Number of classes:  3\n",
      "Number of classes:  4\n"
     ]
    }
   ],
   "source": [
    "# Group the missing values into one classs \n",
    "for ii in quality:\n",
    "    fix_number(ii, threshold = 200, na_value = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region_city                 51408\n",
       "region_county                   0\n",
       "region_neighbor           1817378\n",
       "region_zip                   2543\n",
       "zoning_landuse_county         840\n",
       "type_zoning_landuse             0\n",
       "zoning_property            995151\n",
       "censustractandblock         63689\n",
       "rawcensustractandblock          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of missing values in position features excluding latitude and longitude\n",
    "position = [\"region_city\", \"region_county\", \"region_neighbor\", \"region_zip\", \"zoning_landuse_county\", \n",
    "            \"type_zoning_landuse\", \"zoning_property\", \"censustractandblock\", \"rawcensustractandblock\"]\n",
    "\n",
    "pd.isnull(prop[position]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fillna_knn(target, k=100):\n",
    "    '''\n",
    "    this function imputes the missing position values using k-nearest neighbors method\n",
    "    '''\n",
    "    gps = ['latitude', 'longitude']\n",
    "    \n",
    "    index = pd.isnull(prop[target])\n",
    "    Y = prop.loc[index, gps]\n",
    "    X = prop.loc[~index, [target] + gps]\n",
    "\n",
    "    print \"Size of the missing data: \", Y.shape\n",
    "    print \"Size of the data: \", X.shape\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(X[target].values))\n",
    "    X[target] = lbl.transform(list(X[target].values))\n",
    "\n",
    "    print \"Number of classes: \", X[target].max() + 1\n",
    "    \n",
    "    clf = neighbors.KNeighborsClassifier( n_neighbors = k, weights = 'uniform', n_jobs = 8 )\n",
    "    clf.fit(X.drop(target, axis=1), X[target])\n",
    "    \n",
    "    Y[target] = clf.predict(Y)\n",
    "    \n",
    "    prop.loc[index, target] = Y[target].values\n",
    "    prop.loc[~index, target] = X[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_zip\n",
      "Size of the missing data:  (2543, 2)\n",
      "Size of the data:  (2971237, 3)\n",
      "Number of classes:  405\n",
      "zoning_landuse_county\n",
      "Size of the missing data:  (840, 2)\n",
      "Size of the data:  (2972940, 3)\n",
      "Number of classes:  240\n"
     ]
    }
   ],
   "source": [
    "# impute missing value\n",
    "position_miss = [\"region_zip\", \"zoning_landuse_county\"]\n",
    "for ii in position_miss:\n",
    "    print ii\n",
    "    fillna_knn(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert objects to int\n"
     ]
    }
   ],
   "source": [
    "# convert objects to int\n",
    "object_type = [\"zoning_property\", \"zoning_landuse_county\"]\n",
    "print(\"convert objects to int\")\n",
    "for c in object_type:\n",
    "    prop[c]=prop[c].fillna(-2)\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(prop[c].values))\n",
    "    prop[c] = lbl.transform(list(prop[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert region features to int\n"
     ]
    }
   ],
   "source": [
    "# impute missing values by combining them into a new group\n",
    "region = [\"region_zip\", \"region_city\", \"region_county\", \"region_neighbor\", \"type_zoning_landuse\", \"censustractandblock\", \"rawcensustractandblock\"]\n",
    "print(\"convert region features to int\")\n",
    "for c in region:\n",
    "    prop[c]=prop[c].fillna(-2)\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(prop[c].values))\n",
    "    prop[c] = lbl.transform(list(prop[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the missing data:  (48491, 2)\n",
      "Size of the data:  (2925289, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def fillna_knn_reg(target, k=100):\n",
    "    '''\n",
    "    this function uses the KNeighborsRegressor to impute the missing values for the build_year\n",
    "    '''\n",
    "    gps = ['latitude', 'longitude']\n",
    "    \n",
    "    index = pd.isnull(prop[target])\n",
    "    Y = prop.loc[index, gps]\n",
    "    X = prop.loc[~index, [target] + gps]\n",
    "\n",
    "    print \"Size of the missing data: \", Y.shape\n",
    "    print \"Size of the data: \", X.shape\n",
    "       \n",
    "    clf = neighbors.KNeighborsRegressor( n_neighbors = k, weights = 'uniform' )\n",
    "    clf.fit(X.drop(target, axis=1), X[target])\n",
    "    \n",
    "    Y[target] = clf.predict(Y)\n",
    "    \n",
    "    prop.loc[index, target] = Y[target].values\n",
    "    prop.loc[~index, target] = X[target].values\n",
    "    \n",
    "fillna_knn_reg(\"build_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding to float32\n"
     ]
    }
   ],
   "source": [
    "# convert data type to save some memory\n",
    "for c in number:\n",
    "    prop[c] = prop[c].astype(np.int8)\n",
    "    \n",
    "for c in quality:\n",
    "    prop[c] = prop[c].astype(np.int8)\n",
    "    \n",
    "for c in position:\n",
    "    prop[c] = prop[c].astype(np.int16)\n",
    "    \n",
    "print('Binding to float32')\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        prop[c] = prop[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add new features\n",
    "prop[\"area_ratio\"] = prop[\"area_total_calc\"] / prop[\"area_lot\"]\n",
    "prop[\"tax_building_area\"] = prop[\"tax_building\"] / (prop[\"area_lot\"])\n",
    "prop[\"tax_property_area\"] = prop[\"tax_property\"] / (prop[\"area_lot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the average value of selected features in different region and then\n",
    "# calculate the difference between the average and exact value\n",
    "ll1 = ['region_zip', 'region_neighbor', 'zoning_landuse_county', 'region_city']\n",
    "ll2 = ['zip', 'neighbor', 'zon', 'city']\n",
    "fea = [\"area_lot\", \"area_total_calc\", \"tax_building\",  \"tax_property\", \"latitude\", \"longitude\", \"tax_total\",\n",
    "       \"tax_property_area\", \"tax_building_area\", \"build_year\", \"num_bedroom\", \"num_bathroom\"]\n",
    "\n",
    "for c1, c2 in zip(ll1, ll2):\n",
    "    for cc in fea:\n",
    "        ave = prop.groupby(c1)[cc].mean().to_dict()\n",
    "        name1 = c2 + \"_\" + cc\n",
    "        prop[name1] = prop[c1].map(ave)\n",
    "        name2 = name1 + \"_diff\"\n",
    "        prop[name2] = prop[cc] - prop[name1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the number of houses in each region and add them as new features\n",
    "ll = ['region_zip', 'region_city', 'region_neighbor', 'type_zoning_landuse']\n",
    "for c in ll:\n",
    "    count = prop[c].value_counts().to_dict()\n",
    "    name = c + \"_count\"\n",
    "    prop[name] = prop[c].map(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read location file\n",
      "(2973780, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the converted coordinates (from cartesian to polar) and add then to the dataset \n",
    "print \"Read location file\"\n",
    "coord = pd.read_csv(path + \"location2.csv\")\n",
    "print coord.shape\n",
    "\n",
    "prop = pd.merge(prop, coord.drop([\"latitude\", \"longitude\"], axis = 1), how='left', on='id_parcel')\n",
    "del coord\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding to float32\n"
     ]
    }
   ],
   "source": [
    "print('Binding to float32')\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        prop[c] = prop[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read cluster file\n",
      "(2973780, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the cluster data\n",
    "print \"Read cluster file\"\n",
    "clusters = pd.read_csv(path + \"n_clusters2.csv\")\n",
    "print clusters.shape\n",
    "\n",
    "prop = pd.merge(prop, clusters, how='left', on='id_parcel')\n",
    "del clusters\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = ['cluster0', 'cluster1', 'cluster2', 'cluster3', 'cluster4', 'cluster5']\n",
    "for c in clusters:\n",
    "    count = prop[c].value_counts().to_dict()\n",
    "    name = c + \"_count\"\n",
    "    prop[name] = prop[c].map(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the deviation from the averages of different features in three selected clusters\n",
    "clusters = ['cluster1', 'cluster2', 'cluster3'] \n",
    "clusters2 = ['cl1', 'cl2', 'cl3']\n",
    "    \n",
    "fea = [\"area_lot\", \"area_total_calc\", \"tax_building\",  \"tax_property\", \"latitude\", \"longitude\", \"tax_total\",\n",
    "       \"tax_property_area\", \"tax_building_area\", \"build_year\", \"num_bedroom\", \"num_bathroom\"]\n",
    "\n",
    "for c1, c2 in zip(clusters, clusters2):\n",
    "    for cc in fea:\n",
    "        ave = prop.groupby(c1)[cc].mean().to_dict()\n",
    "        name1 = c2 + \"_\" + cc\n",
    "        prop[name1] = prop[c1].map(ave)\n",
    "        name2 = name1 + \"_diff\"\n",
    "        prop[name2] = prop[cc] - prop[name1]\n",
    "        \n",
    "        prop[name1] = prop[name1].astype(np.float32)\n",
    "        prop[name2] = prop[name2].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the neighbor file and merging with prop...\n"
     ]
    }
   ],
   "source": [
    "# Read the nearest neighbor data and merge them with prop\n",
    "print \"Reading the neighbor file and merging with prop...\"\n",
    "kname = \"k50\"\n",
    "kneighbor = pd.read_csv(path + kname + \".csv\")\n",
    "prop = pd.merge(prop, kneighbor, how='left', on='id_parcel')\n",
    "del kneighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rname = \"r150\"\n",
    "rneighbor = pd.read_csv(path + rname + \".csv\")\n",
    "features = ['area_lot', 'tax_property', 'build_year', 'area_total_calc', 'tax_building',\n",
    "            'tax_total']\n",
    "prop = pd.merge(prop, rneighbor, on=\"id_parcel\", how=\"left\")\n",
    "\n",
    "features2 = rneighbor.columns[2:]\n",
    "\n",
    "for cc1, cc2 in zip(features, features2):\n",
    "    name_diff = rname + \"_\" + cc1 + \"_diff\"\n",
    "    prop[name_diff] = prop[cc1] - prop[cc2]\n",
    "del rneighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop some unimportant features\n",
    "dd = ['type_architectural',\n",
    " 'area_basement',\n",
    " 'num_bathroom',\n",
    " 'num_bedroom',\n",
    " 'type_framing',\n",
    " 'num_bathroom_calc',\n",
    " 'type_deck',\n",
    " 'num_bath',\n",
    " 'pooltypeid10',\n",
    " 'region_county',\n",
    " 'type_story',\n",
    " 'type_material',\n",
    " 'area_shed',\n",
    " 'tax_year',\n",
    " 'num_rot75_X',\n",
    " 'num_rot75_Y']\n",
    "\n",
    "prop = prop.drop(dd + [\"area_total_calc\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train file and merge with properties to generate train file and taraget\n",
      "Size of the train data frame:  (90275, 57)\n"
     ]
    }
   ],
   "source": [
    "# Read Train again and merge with properties\n",
    "print(\"Read train file and merge with properties to generate train file and taraget\")\n",
    "train = pd.read_csv(path + 'renamed_train_2016.csv', parse_dates=['date'])\n",
    "train = train.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "train[\"month\"] = train['date'].dt.month\n",
    "\n",
    "train = pd.merge(train, prop, how='left', on='id_parcel')\n",
    "train = train.drop(['date'], axis=1)\n",
    "print \"Size of the train data frame: \", train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop duplicates from train dataset\n",
    "duplicate = train[\"id_parcel\"].duplicated(keep='first')\n",
    "train = train[~duplicate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2883630 entries, 0 to 2883629\n",
      "Columns: 260 entries, id_parcel to r150_tax_total_diff\n",
      "dtypes: float32(199), float64(22), int16(8), int64(19), int8(12)\n",
      "memory usage: 3.1 GB\n"
     ]
    }
   ],
   "source": [
    "# Exclude train from prop\n",
    "id_parcel = train[\"id_parcel\"].values\n",
    "prop = prop.set_index(\"id_parcel\")\n",
    "prop = prop.drop(id_parcel)\n",
    "prop = prop.reset_index()\n",
    "prop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the missing\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11437 entries, 0 to 11436\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    11437 non-null int64\n",
      "index         11437 non-null int64\n",
      "id_parcel     11437 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 268.1 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Read the missing\")\n",
    "miss = pd.read_csv(path + 'missing.csv')\n",
    "miss.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the datasets into a binary file for model fitting\n",
    "store = pd.HDFStore(path + 'store_2016.h5')\n",
    "store[\"prop\"] = prop\n",
    "store[\"train\"] = train\n",
    "store[\"miss\"] = miss\n",
    "store.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
