{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramezani/anaconda/lib/python2.7/site-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the properties and merge with coord\n",
      "Size of the properties data frame:  (2985217, 3)\n"
     ]
    }
   ],
   "source": [
    "path = \"../../../../data/\"\n",
    "print(\"Read the properties and merge with coord\")\n",
    "coord = pd.read_csv(path + 'renamed_properties_2017.csv', usecols = [\"id_parcel\", \"latitude\", \"longitude\"])\n",
    "print \"Size of the properties data frame: \", coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the properties data frame:  (2985217, 7)\n"
     ]
    }
   ],
   "source": [
    "features = [\"id_parcel\", \"area_lot\", \"tax_property\", \"build_year\", \"area_total_calc\", \"tax_building\", \"tax_total\"]\n",
    "\n",
    "prop = pd.read_csv(path + 'renamed_properties_2017.csv', usecols = features)\n",
    "print \"Size of the properties data frame: \", prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the properties data frame:  (2982285, 3)\n",
      "Size of the properties data frame:  (2982285, 7)\n"
     ]
    }
   ],
   "source": [
    "index = pd.isnull(coord[\"latitude\"])\n",
    "coord = coord[~index]\n",
    "prop = prop[~index]\n",
    "print \"Size of the properties data frame: \", coord.shape\n",
    "print \"Size of the properties data frame: \", prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.latitude = coord.latitude / 1e6\n",
    "coord.longitude = coord.longitude / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train file and merge with properties to generate train file and taraget\n"
     ]
    }
   ],
   "source": [
    "# Read Train\n",
    "print(\"Read train file and merge with properties to generate train file and taraget\")\n",
    "path = '../../../../data/'\n",
    "train_2016 = pd.read_csv(path + 'renamed_train_2016.csv', parse_dates=['date'])\n",
    "train_2016 = train_2016.drop(\"Unnamed: 0\", axis=1)\n",
    "train_coord_2016 = pd.merge(train_2016, coord, how='left', on='id_parcel')\n",
    "train_coord_2016 = train_coord_2016.drop(['date', 'logerror'], axis=1)\n",
    "\n",
    "train_2017 = pd.read_csv(path + 'renamed_train_2017.csv', parse_dates=['date'])\n",
    "train_2017 = train_2017.drop(\"Unnamed: 0\", axis=1)\n",
    "train_coord_2017 = pd.merge(train_2017, coord, how='left', on='id_parcel')\n",
    "train_coord_2017 = train_coord_2017.drop(['date', 'logerror'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate 2016 and 2017 train\n",
    "train_coord = pd.concat([train_coord_2016, train_coord_2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = pd.isnull(train_coord[\"latitude\"])\n",
    "train_coord = train_coord[~index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cores 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print \"number of cores \" + str(num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 333, 666, 999, 1332, 1665, 1998, 2000]\n"
     ]
    }
   ],
   "source": [
    "def splitDataFrameIntoSmaller(df, chunkSize = 100000): \n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(i*chunkSize)\n",
    "    listOfDf.append(len(df))\n",
    "    return listOfDf\n",
    "\n",
    "split_index = splitDataFrameIntoSmaller(prop, chunkSize=coord.shape[0]/num_cores)\n",
    "print split_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_avg(n1, n2, cc):\n",
    "    avg_list = []\n",
    "    for ii in range(n1, n2):\n",
    "        index = np.setdiff1d(indices[ii], ii)\n",
    "        avg = prop.loc[index, cc].mean()\n",
    "        avg_list.append(avg)\n",
    "    return avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\"area_lot\", \"tax_property\", \"build_year\", \"area_total_calc\", \"tax_building\", \"tax_total\"]\n",
    "feat_avg = [\"area_lot_avg\", \"tax_property_avg\", \"build_year_avg\", \"area_total_calc_avg\", \n",
    "            \"tax_building_avg\", \"tax_total_avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(n_neighbors=10000, algorithm='ball_tree', \n",
    "                        n_jobs = num_cores).fit(coord.loc[:, [\"latitude\", \"longitude\"]])\n",
    "knn_train = NearestNeighbors(n_neighbors=10000, algorithm='ball_tree', \n",
    "                        n_jobs = num_cores).fit(train_coord.loc[:, [\"latitude\", \"longitude\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder k5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramezani/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:16: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k5 area_lot_avg\n",
      "k5 tax_property_avg\n",
      "k5 build_year_avg\n",
      "k5 area_total_calc_avg\n",
      "k5 tax_building_avg\n",
      "k5 tax_total_avg\n"
     ]
    }
   ],
   "source": [
    "for k in [5]:\n",
    "#for k in [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "    ss = \"k\" + str(k)\n",
    "    print \"Folder \" + ss\n",
    "    \n",
    "    #get the distances, indices, and compute the min and max ditances\n",
    "    distances, indices  = knn.kneighbors(coord.loc[:, [\"latitude\", \"longitude\"]], n_neighbors = k,\n",
    "                                          return_distance = True)\n",
    "    \n",
    "    rmax = []\n",
    "    rmin = []\n",
    "    minmax_ratio = []\n",
    "    for ii in distances:\n",
    "        rmax.append(max(ii))\n",
    "        rmin.append(min(ii[1:]))\n",
    "        minmax_ratio.append(max(ii)/min(ii[1:]))\n",
    "        \n",
    "    prop['rmax'] = rmax\n",
    "    prop['rmin'] = rmin\n",
    "    prop['minmax_ratio'] = minmax_ratio\n",
    "    \n",
    "    dist_train, ind_train  = knn_train.kneighbors(coord.loc[:, [\"latitude\", \"longitude\"]], n_neighbors = k,\n",
    "                                          return_distance = True)\n",
    "    \n",
    "    rtran = []\n",
    "    for ii in dist_train:\n",
    "        rtran.append(max(ii))\n",
    "        \n",
    "    prop['rtran'] = rtran\n",
    "    \n",
    "    for f1, f2 in zip(features, feat_avg):\n",
    "        multi = Parallel(n_jobs=4)(delayed(knn_avg)(split_index[i], split_index[i+1], f1)\n",
    "                                   for i in range(0,len(split_index)-1))\n",
    "    \n",
    "        single = [x for xx in multi for x in xx]\n",
    "    \n",
    "        ss2 = f2 #ss + \"_\" + f2\n",
    "        prop[ss2] = single\n",
    "        print ss, f2\n",
    "        \n",
    "    name = ss + \".csv\"\n",
    "    prop[[\"id_parcel\", 'rmax', 'rmin', 'minmax_ratio', 'rtran'] + feat_avg].to_csv('../../'+name, index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
